\chapter{Wstęp}
\thispagestyle{chapterBeginStyle}

W tej pracy zajmiemy się problemem zliczania unikalnych elementów w strumieniach danych, który coraz częściej pojawia się w dużych systemach przetwarzania danych i środowiskach OLAP (Online Analytical Data Processing). Bardzo często mamy do czynienia z ogromnym napływem danych do analizy a próba dokładnego zliczania unikalnych elementów w strumieniu kończy się ogromnym zapotrzebowaniem pamięciowym, ponieważ jesteśmy zmuszeni pamiętać wszystkie napotkane dotychczas elementy.

Takie podejście jest bardzo niewydajne, gdyż biorąc pod uwagę jak wiele urządzeń oraz aplikacji generuje dzisiaj dane oraz w jak dużych ilościach one napływają (np. logi napływające w tysiącach wpisów na sekundę) potrzebowalibyśmy setek terabajtów pamięci żeby być w stanie je przechowywać, a przestrzeń ta będzie rosła z każdym kolejnym napływającym wpisem.

Żeby poradzić sobie z tym problemem zaproponowano metody aproksymacyjne, które pozawalają zliczać unikalne elementy z pewnym - stosunkowo niedużym - błędem, ale za to wymagające nieporównywalnie mniej pamięci. Algorytmy te operują na tak zwanych szkicach danych będących ich uproszczoną reprezentacją (np. w postaci haszy elementów). Jednym z pierwszych takich algorytmów był \textit{Probabilistic Counting}, który później ewoluował w algorytm \textit{LogLog}, a ostatecznie w bardzo popularny i szeroko używany dzisiaj algorytm \textit{HyperLogLog}. Kolejnym z algorytmów jest algorytm oparty na k-tej statystyce pozycyjnej, nazywany również \textit{MinCount}, który zostanie również szeroko omówiony w tej pracy. Oprócz tego istnieje jeszcze wiele innych algorytmów zliczania takich jak np. \textit{Multiresolution Bitmap, S-Bitmap czy MaxCount}.

W niniejszej pracy zajmiemy się głównie omówieniem algorytmów i metod aplikacji operacji teoriomnogościowych na szkicach danych, które znajdują coraz większe zastosowanie wśród dużych aplikacji wykonujących skomplikowane zapytania i agregacje. Jako przykład weźmy sytuację gdy chcemy zliczać wejścia unikatowych użytkowników na naszą stronę internetową. Średnio stronę odwiedza około 100 osób na sekundę. Próba dokładnego zliczania unikalnych adresów IP odwiedzających szybko okaże się nieefektywna zabierając zbyt wiele pamięci. Powinniśmy zatem użyć jednej z metod aproksymacyjnych do stworzenia szkiców odpowiadających wejściom użytkowników na stronę. Ale co jeśli chcielibyśmy zbierać te dane w określonych przedziałach czasowych, np. co 24 godziny, albo co godzinę? W takiej sytuacji bardzo przydatnym narzędziem byłaby możliwość dalszej agregacji tych szkiców danych wykonując na przykład sumę na jakiejś liczbie szkiców godzinnych celem uzyskania liczby unikalnych wejść z ostatnich kilku dni. Możliwość wykonywania sum lub innych operacji teoriomnogościowych daje nam możliwość wykorzystania takich mniejszych szkiców o małej granulacji czasowej do agregacji w dowolnie większe zbiory - bez tych operacji musielibyśmy tworzyć nowe szkice dla każdej innej granulacji czasowej, nawet jeżeli różniłaby się ona bardzo niewiele, np. o godzinę. Takie podejście umożliwia również zliczanie unikalnych elementów w środowisku rozproszonym. Przykładowo, moglibyśmy rozbić jakiś duży strumień danych na kilka podstrumieni i tworzyć dla każdego nich równolegle osobne szkice, a następnie zagregować je przy pomocy sumy.

Praca ta została podzielona na pięć rozdziałów. W rozdziale pierwszym zajmiemy się dokładniejszą analizą interesujących nas algorytmów aproksymacyjnych zliczania: \textit{MinCount} oraz \textit{HyperLogLog} - zdefiniujemy te algorytmy, opiszemy i udowodnimy ich własności takie jak wartość oczekiwana, wariancja jak również błąd standardowy. Omówimy tam również naiwne podejście dla operacji teoriomnogościowych korzystające z zasady włączeń i wyłączeń oraz indeksów \textit{Jaccarda}. W rozdziale drugim zajmiemy się dokładniej operacjami sumy i przekroju na szkicach oraz możliwościami ich udoskonalenia poprzez zastosowanie pewnych pomysłów i ulepszeń dla algorytmów \textit{MinCount} oraz \textit{HyperLogLog}. W kolejnym rozdziale omówimy metodę \textit{estymatora ważonego} przedstawioną w \cite{ting} dla sum i przekrojów na szkicach dla algorytmu \textit{MinCout} oraz postaramy się ją uogólnić dla algorytmu \textit{HyperLogLog} oraz pokazać jak zastosować tę metodę do policzenia różnicy szkiców. W rozdziale czwartym przyjrzymy się też tematowi kolejności wykonywania operacji na wielu zbiorach oraz przedstawimy wyniki eksperymentów dla różnych metod. W ostatnim rozdziale przedstawimy wyniki testów opisanych wcześniej metod oraz ulepszeń algorytmów i wyciągniemy wnioski podsumowując skuteczność oraz praktyczne zastosowanie tych algorytmów.