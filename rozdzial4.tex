\chapter{Wyniki eksperymentów}
\thispagestyle{chapterBeginStyle}

W tym rozdziale przyjrzymy się wynikom  eksperymentów przeprowadzonych dla omawianych wcześniej algorytmów i ich modyfikacji. Na początku rozważymy rozwiązania oparte o algorytm \texttt{Streaming MinCount}. 
Porównamy podejście naiwne, podejście wykorzystujące ulepszenia przedstawione w rozdziale \ref{impr_mincount} oraz metodę \textit{estymatora ważonego}. Pokażemy również wyniki dla zaproponowanego przez nas w rozdziale \ref{diff_weighted} estymatora operacji różnicy.

 Następnie dla algorytmu \texttt{HyperLogLog}, 
  %\JL{Dlaczego niby tylko na przekroju,  to podejrzane tak pisac, nawet jesli my wiemy o co chodzi}
 porównamy podejście naiwne, korzystające z indeksu \textit{Jaccarda} i metodę estymatora \textit{ważonego} dla tegoż algorytmu, zaprezentowaną w rozdziale \ref{hll_weighted}. Na koniec porównamy efektywność obu algorytmów w kontekście operacji teoriomnogościowych i postaramy się określić które z nich sprawdzą się najefektywniej w praktyce. 
%\AW{Nie jestem pewien czy porównywac ze soba wprost te dwa algorytmy (MinCount i HLL) - nie mam do tego jakichs sensownych eksperymentów, trzebaby je jakos zbadac przy wykorzystaniu podobnej ilosci pamieci albo cos w tym stylu - moglibysmy to pozostawic moze jako otwarta kwestię do sprawdzenia w ''przyszlosci''? Jak Pan sądzi?}
%\JL{Ja bym napisal, ze HLL bedzie potrzebowala znacznie mniej pamieci zeby uzyskac tą samą dokladnosc, wiec nie bedziemy ich tutaj porownywac, no chyba, że wymysli Pan jakis sensowny eksperyment}

Eksperymenty przeprowadzone w tym rozdziale badają dokładność estymacji dla różnych wartości indeksów \textit{Jaccarda} dla zbiorów, na których wykonywane są operacje. Dokładność algorytmu mierzymy przez $\frac{\hat{n}}{n}$, czyli stosunek estymacji liczności danego zbioru wyznaczonej do prawdziwej liczności zbioru. Na każdy punkt na wykresie przypada 100 eksperymentów, z których następnie wyliczyliśmy średnią i tą wartość nanieśliśmy na wykres.

\section{Wyniki dla algorytmu Streaming MinCount}
%\AW{Wstawilem nowe wykresy dla MC}
Na początek przedstawiamy wyniki dla trzech metod estymacji dla algorytmu \texttt{Streaming MinCount}:
\begin{enumerate}
	\item metoda naiwna (z \textit{zasady włączeń i wyłączeń}),
	\item ulepszenia zaproponowane w rozdziałach \ref{impr_sum} oraz \ref{impr_inter},
	\item metoda \textit{estymatora ważonego}.
\end{enumerate}
We wszystkich eksperymentach dla tego algorytmu, ustaliliśmy parametr $k = 100$, czyli szkice przetrzymywały 100 najmniejszych haszy.
Na wykresach przedstawiamy wartości $\eta = \frac{\hat{n}}{n}$ dla poszczególnych metod, oznaczone na legendzie przez odpowiednio:
\begin{enumerate}
	\item \textbf{err\_naive}
	\item \textbf{err\_impr}
	\item \textbf{err\_reweigh}
\end{enumerate}
Wykresy \ref{fig:KMV_2sets_inter} oraz \ref{fig:KMV_2sets_unions} przedstawiają wyniki eksperymentów dla sum i przekrojów dwóch zbiorów.

\begin{figure}[h!]
    \includegraphics[width=0.6\textwidth]{KMV_2_sets_inter.png}
    \centering
    \caption{Porównanie metod dla przekrojów 2 zbiorów przy $n=10^5$}
    \label{fig:KMV_2sets_inter}
\end{figure}

\begin{figure}[h!]
    \includegraphics[width=0.6\textwidth]{KMV_2_sets_unions.png}
    \centering
    \caption{Porównanie metod dla sumy 2 zbiorów przy $n=10^5$}
    \label{fig:KMV_2sets_unions}
\end{figure}

Zauważmy, że dla operacji sumy - praktycznie na całym przedziale indeksów \textit{Jaccarda} zbiorów - najmniejszy błąd posiada metoda \textit{estymatora ważonego}. W przypadku przekroju - metody $2.$ oraz $3.$ wypadają o wiele lepiej niż metoda naiwna. Na wykresie możemy zauważyć, że metoda \textit{estymatora ważonego} dla większości indeksów \textit{Jaccarda} ma podobną wariancję do metody $2.$, ale za to nieco mniejsze obciążenie.
%\JL{Ja bym napisał: że dla wiekszosci indeksow Jaccarda ważona ma nieco mniejsze obciążenie i podobną wariancję.Nie za bardzo wiem co to jest tendencja...}

Na kolejnych wykresach: \ref{fig:KMV_10sets_inter}, \ref{fig:KMV_10sets_unions}, \ref{fig:KMV_100sets_inter} oraz \ref{fig:KMV_100sets_unions}, zestawiliśmy wyniki dla sum i przekrojów większej liczby zbiorów. Wykonaliśmy eksperymenty dla 10 oraz 50 zbiorów o mocach $n = 10^5$, porównując metody $2.$ oraz $3.$ Metodę naiwną pominęliśmy ze względu na jej znaczące wady opisane w rozdziale \ref{naive_est}. 

Możemy zauważyć, że również jak na poprzednich wykresach dla dwóch zbiorów - metoda \textit{estymatora ważonego} ma widocznie mniejsze obciążenie oraz nieco mniejszą wariancję niż metoda $2.$ - zwłaszcza dla dużych \textit{indeksów Jaccarda}.
%\JL{Zamiast tej tendencji tu bym napisał, że ważony ma widocznie mniejsze obciążenie i nieco mniejszą wariancję.}

%\JL{Gdzie jest napisane ile eksperymentów przypada na jeden punkt  na wykresie? Jak nie ma to by się przydało napisać.}
\begin{figure}[h!]
    \includegraphics[width=0.6\textwidth]{KMV_10_sets_inter.png}
    \centering
    \caption{Porównanie metod dla przekroju 10 zbiorów}
    \label{fig:KMV_10sets_inter}
\end{figure}

\begin{figure}[h!]
    \includegraphics[width=0.6\textwidth]{KMV_10_sets_unions.png}
    \centering
    \caption{Porównanie metod dla sumy 10 zbiorów}
    \label{fig:KMV_10sets_unions}
\end{figure}

\begin{figure}[h!]
    \includegraphics[width=0.6\textwidth]{KMV_100_sets_inter.png}
    \centering
    \caption{Porównanie metod dla przekroju 50 zbiorów}
    \label{fig:KMV_100sets_inter}
\end{figure}

\begin{figure}[h!]
    \includegraphics[width=0.6\textwidth]{KMV_100_sets_unions.png}
    \centering
    \caption{Porównanie metod dla sumy 50 zbiorów}
    \label{fig:KMV_100sets_unions}
\end{figure}

Ostatnimi eksperymentami przeprowadzonymi dla algorytmu \texttt{MinCount} było sprawdzenie metody \textit{estymatora ważonego} dla różnicy zbiorów, omówionej w rozdziale \ref{diff_weighted}. Na wykresie \ref{fig:KMV_2_sets_diff} przedstawiamy wyniki dla różnicy dwóch zbiorów, porównując podejście naiwne oraz podejście wykorzystujące \textit{estymator ważony}.

\begin{figure}[h!]
    \includegraphics[width=0.6\textwidth]{KMV_2_sets_diff.png}
    \centering
    \caption{Porównanie metod dla różnicy 2 zbiorów}
    \label{fig:KMV_2_sets_diff}
\end{figure}

Zauważmy że metoda \textit{estymatora ważonego} po raz kolejny wypada znacznie lepiej od metody naiwnej i utrzymuje mniej więcej stały błąd niezależnie od wartości \textit{indeksu Jaccarda} zbiorów. Nie możemy tego powiedzieć o metodzie naiwnej, której błąd znacznie rośnie wraz z wzrostem podobieństwa zbiorów.

\newpage
\section{Wyniki dla algorytmu HyperLogLog}
%\AW{przez noc wygeneruje jeszcze dokladniejsze wykresy dla HLL}
W tym podrozdziale przedstawimy wyniki dla algorytmu \texttt{HyperLogLog}. Zestawiliśmy ze sobą dwie metody:
\begin{enumerate}
	\item metoda naiwna z użyciem indeksu \textit{Jaccarda} (wzór (\ref{jacc_1}))
	\item metoda \textit{estymatora ważonego}
\end{enumerate}
Obydwie metody korzystają z pomocniczej struktury dla każdego ze szkiców, przechowującej $k$ najmniejszych wartości (czyli zasadniczo z podstawowej wersji szkicu \texttt{MinCount}), pozwalającej na estymację indeksu \textit{Jaccarda} \cite{adroll}, potrzebnego zarówno do estymacji metodą naiwną jak i metodą \textit{estymatora ważonego}. W przeprowadzanych eksperymentach ustaliliśmy parametry $k = 80$ oraz $p = 8$.
Na wykresach przedstawiamy wartości $\eta = \frac{\hat{n}}{n}$ dla poszczególnych metod, oznaczone na legendzie przez odpowiednio:
\begin{enumerate}
	\item \textbf{err\_naive}
	\item \textbf{err\_reweigh}
\end{enumerate}

Na wykresach \ref{fig:HLL_2_sets_unions}, \ref{fig:HLL_2_sets_unions}, \ref{fig:HLL_10_sets_unions} oraz \ref{fig:HLL_10_sets_inter} przedstawiamy porównanie powyższych metod w kontekście operacji sumy oraz przekroju. Eksperymenty przeprowadziliśmy dla 2 oraz 10 zbiorów o mocach $n=10^5$.

\begin{figure}[h!]
	\includegraphics[width=0.6\textwidth]{HLL_2_sets_inter.png}
	\centering
	\caption{Porównanie metod dla przekroju 2 zbiorów przy $n=10^5$}
	\label{fig:HLL_2_sets_inter}
\end{figure}

\begin{figure}[h!]
	\includegraphics[width=0.6\textwidth]{HLL_2_sets_unions.png}
	\centering
	\caption{Porównanie metod dla sumy 2 zbiorów przy $n=10^5$}
	\label{fig:HLL_2_sets_unions}
\end{figure}

\begin{figure}[h!]
    \includegraphics[width=0.6\textwidth]{HLL_10_sets_inter.png}
    \centering
    \caption{Porównanie metod dla przekroju 10 zbiorów przy $n=10^5$}
    \label{fig:HLL_10_sets_inter}
\end{figure}
\AW{tutaj jest blad w legendzie na wykresie - powinno byc err\_naive zamiast err\_impr!}

\begin{figure}[h!]
    \includegraphics[width=0.6\textwidth]{HLL_10_sets_unions.png}
    \centering
    \caption{Porównanie metod dla sumy 10 zbiorów przy $n=10^5$}
    \label{fig:HLL_10_sets_unions}
\end{figure}

Wnioski wynikające z tych eksperymentów sugerują, że metoda \textit{estymatora ważonego} w kontekście algorytmu \texttt{HyperLogLog} dla operacji sumy niestety nie dorównuje pod względem dokładności podejściu naiwnemu. W przypadku sumy jest to dosyć oczywiste, ponieważ jak wspominaliśmy w rozdziale 2 - \texttt{HyperLogLog} posiada naturalną operację sumy. W przypadku operacji przekroju metoda naiwna wykorzystująca indeks \textit{Jaccarda} i wzór (\ref{jacc_1}) posiada większy błąd niż estymacja z użyciem \textit{estymatora ważonego}, zwłaszcza dla zbiorów o niskim podobieństwie. Zauważmy że obie metody wykorzystują tyle samo pamięci, bowiem obie wymagają dodatkowej struktury pozwalającej na estymację indeksu \textit{Jaccarda} przy wykorzystaniu algorytmu \texttt{MinHash}.

\section{Porównanie algorytmów Streaming MinCount i HyperLogLog}

W tym podrozdziale przedstawiamy wyniki porównania algorytmów \texttt{Streaming MinCount} oraz \texttt{HyperLogLog}. Aby porównać oba algorytmy, dopasowaliśmy ich parametry tak, aby oba algorytmy wykorzystywały tą sama ilość pamięci. Na wykresach \ref{fig:HLL_KMV_2_sets_unions} oraz \ref{fig:HLL_KMV_10_sets_unions} przedstawiamy porównanie wartości $\eta = \frac{\hat{n}}{n}$ najlepszych metod dla poszczególnych algorytmów w kontekście operacji sumowania, przy liczności testowych zbiorów $n=10^5$:
\begin{enumerate}
	\item metoda \textit{estymatora ważonego} dla algorytmu \texttt{Streaming MinCount} - \textbf{err\_MC}
	\item naturalna metoda sumowania dla algorytmu \texttt{HyperLogLog} (zobacz \ref{HLL_sum}) - \textbf{err\_HLL}
\end{enumerate}

\begin{figure}[h!]
	\includegraphics[width=0.6\textwidth]{HLL_KMV_2_sets_unions.png}
	\centering
	\caption{Porównanie algorytmów dla sumy 2 zbiorów przy $n=10^5$}
	\label{fig:HLL_KMV_2_sets_unions}
\end{figure}

\begin{figure}[h!]
	\includegraphics[width=0.6\textwidth]{HLL_KMV_10_sets_unions.png}
	\centering
	\caption{Porównanie algorytmów dla sumy 10 zbiorów przy $n=10^5$}
	\label{fig:HLL_KMV_10_sets_unions}
\end{figure}
W przypadku operacji sumowania zbiorów, algorytm \texttt{HyperLogLog} wypada zdecydowanie lepiej, zwłaszcza dla większej liczby zbiorów. Ta obserwacja utwierdza nas w przekonaniu że naturalna operacja sumy, którą posiada szkic algorytmu \texttt{HyperLogLog} jest najefektywniejsza i jak wynika z naszych eksperymentów - sprawdza się lepiej niż algorytm \texttt{Streaming MinCount}, przy takim samym wykorzystaniu pamięci.

Na wykresach \ref{fig:HLL_KMV_2_sets_inter} oraz \ref{fig:HLL_KMV_10_sets_inter} przedstawiamy porównanie wartości $\eta = \frac{\hat{n}}{n}$ najlepszych metod dla poszczególnych algorytmów w kontekście operacji przekroju, przy liczności testowych zbiorów $n=10^5$:
\begin{enumerate}
	\item metoda \textit{estymatora ważonego} dla algorytmu \texttt{Streaming MinCount} - \textbf{err\_MC},
	\item metoda \textit{estymatora ważonego} dla algorytmu \texttt{HyperLogLog} - \textbf{err\_HLL}.
\end{enumerate}

\begin{figure}[h!]
	\includegraphics[width=0.6\textwidth]{HLL_KMV_2_sets_inter.png}
	\centering
	\caption{Porównanie algorytmów dla przekroju 2 zbiorów przy $n=10^5$}
	\label{fig:HLL_KMV_2_sets_inter}
\end{figure}

\begin{figure}[h!]
	\includegraphics[width=0.6\textwidth]{HLL_KMV_10_sets_inter.png}
	\centering
	\caption{Porównanie algorytmów dla przekroju 10 zbiorów przy $n=10^5$}
	\label{fig:HLL_KMV_10_sets_inter}
\end{figure}

W przypadku przekrojów sytuacja nie jest tak oczywista jak dla sumy. Dla dwóch zbiorów, wyniki sugerują, że algorytmy sprawują się porównywalnie. 
%JL
Algorytm \texttt{Streaming MinCount} daje wyniki o nieco mniejszej wariancji, ale widocznym obciążeniu. 
%\JL{To zdanie zmieniłem, bo było zbyt naciagane moim zdaniem} 
%JL- z niewielką przewaga algorytmu \texttt{Streaming MinCount} na przedziale indeksów \textit{Jaccarda} od ok $0.20$ do $0.85$. 
Symulacje dla 10 zbiorów potwierdzają, że wyniki \texttt{Streaming MinCount} są istotnie bardziej obciążone, 
zwłaszcza dla większych wartości indeksu \textit{Jaccarda}.
W tym scenariuszu wyniki dla algorytmu \texttt{HyperLogLog} wydają się prawie nieobciążone i mają stosunkowo niewielką wariancję.
%JL - tutaj też trochę zmieniłem
%że algorytmy zachowują się podobnie gdy podobieństwo zbiorów jest mniejsze niż $0.50$. Jednak dla większych indeksów \textit{Jaccarda} przewagę uzyskuje algorytm \texttt{HyperLogLog}.

